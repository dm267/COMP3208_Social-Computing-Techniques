{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ratingsTrainLarge = pd.read_csv('comp3208-train.csv', header=None)\n",
    "ratingsTrainLarge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd91a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misses first row when we do this???\n",
    "ratingsTrainLargeDataframe=pd.DataFrame(ratingsTrainLarge.values, columns = [\"UserID\", \"ItemID\", \"Rating\", \"Timestamp\"])\n",
    "ratingsTrainLargeDataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ratingsTrainLargeDataframe.groupby('UserID')['Rating'].count()\n",
    "top_users = a.sort_values(ascending=False)[:15]\n",
    "\n",
    "b = ratingsTrainLargeDataframe.groupby('ItemID')['Rating'].count()\n",
    "top_items = b.sort_values(ascending=False)[:15]\n",
    "\n",
    "top_ratings = ratingsTrainLargeDataframe.join(top_users, rsuffix='_ratings', how='inner', on='UserID')\n",
    "top_ratings = top_ratings.join(top_items, rsuffix='_ratings', how='inner', on='ItemID')\n",
    "\n",
    "pd.crosstab(top_ratings.UserID, top_ratings.ItemID, top_ratings.Rating, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ee930",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoderLarge = LabelEncoder()\n",
    "ratingsTrainLargeDataframe['UserID'] = user_encoderLarge.fit_transform(ratingsTrainLargeDataframe['UserID'].values)\n",
    "n_users = ratingsTrainLargeDataframe['UserID'].nunique()\n",
    "\n",
    "item_encoderLarge = LabelEncoder()\n",
    "ratingsTrainLargeDataframe['ItemID'] = item_encoderLarge.fit_transform(ratingsTrainLargeDataframe['ItemID'].values)\n",
    "n_items = ratingsTrainLargeDataframe['ItemID'].nunique()\n",
    "\n",
    "#ratingsDataframe['Rating'] = ratingsDataframe['Rating'].astype(str).str.replace(r'(\\rating', '0')\n",
    "\n",
    "ratingsTrainLargeDataframe['Rating'] = ratingsTrainLargeDataframe['Rating'].astype(str).str.replace(\"rating\",\"3.5\")\n",
    "ratingsTrainLargeDataframe['Rating'] = ratingsTrainLargeDataframe['Rating'].values.astype(np.float32)\n",
    "\n",
    "min_rating = min(ratingsTrainLargeDataframe['Rating'].values.astype(np.float32))\n",
    "max_rating = max(ratingsTrainLargeDataframe['Rating'].values.astype(np.float32))\n",
    "\n",
    "#n_users, n_items, min_rating, max_rating\n",
    "\n",
    "#(671, 9066, 0.5, 5.0)\n",
    "#(274246, 19807, 0.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3002da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratingsTrainLargeDataframe[['UserID', 'ItemID']].values\n",
    "y = ratingsTrainLargeDataframe['Rating'].values\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#X_train.shape, X_validation.shape, y_train.shape, y_validation.shape\n",
    "#n_factors = 50\n",
    "\n",
    "#((90003, 2), (10001, 2), (90003,), (10001,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 50\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_validation_array = [X_validation[:, 0], X_validation[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Add, Activation, Lambda, Input, Reshape, Dot, Embedding\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "modelCheckpoint = ModelCheckpoint('bestModelLarge.h5', monitor='val_loss', mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "# load a saved model\n",
    "#saved_model = load_model('bestModel.h5')\n",
    "\n",
    "\n",
    "class EmbeddingLayer:\n",
    "    def __init__(self, n_items, n_factors):\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = Embedding(self.n_items,\n",
    "                      self.n_factors,\n",
    "                      embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(x)\n",
    "        x = Reshape((self.n_factors,))(x)\n",
    "        return x\n",
    "\n",
    "def RecommenderV2(n_users, n_movies, n_factors, min_rating, max_rating):\n",
    "    user = Input(shape=(1,))\n",
    "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
    "    ub = EmbeddingLayer(n_users, 1)(user)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    mb = EmbeddingLayer(n_movies, 1)(movie)\n",
    "    x = Dot(axes=1)([u, m])\n",
    "    x = Add()([x, ub, mb])\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderV2(n_users, n_items, n_factors, min_rating, max_rating)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66534a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train_array,\n",
    "                    y=y_train,\n",
    "                    batch_size=64000,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_validation_array, y_validation),\n",
    "                    callbacks=[earlyStopping, modelCheckpoint]) \n",
    "\n",
    "#lr=0.001\n",
    "#Epoch 00011: val_loss improved from 0.70822 to 0.70743, saving model to bestModel.h5\n",
    "#475/475 [==============================] - 93s 196ms/step - loss: 0.6295 - val_loss: 0.7074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be5bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d806c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775f25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f25234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTestLarge  = pd.read_csv('comp3208-test.csv', header=None)\n",
    "ratingsTestLargeDataframe=pd.DataFrame(ratingsTestLarge.values, columns = [\"UserID\", \"ItemID\", \"Timestamp\"])\n",
    "ratingsTestLargeDataframe.insert(2, 'Rating', '')\n",
    "ratingsTestLargeDataframe.head()\n",
    "#ratingsTestSmallDataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aba50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoderLargeTest = LabelEncoder()\n",
    "ratingsTestLargeDataframe['UserID'] = user_encoderLargeTest.fit_transform(ratingsTestLargeDataframe['UserID'].values)\n",
    "n_users = ratingsTestLargeDataframe['UserID'].nunique()\n",
    "\n",
    "item_encoderLargeTest = LabelEncoder()\n",
    "ratingsTestLargeDataframe['ItemID'] = item_encoderLargeTest.fit_transform(ratingsTestLargeDataframe['ItemID'].values)\n",
    "n_items = ratingsTestLargeDataframe['ItemID'].nunique()\n",
    "\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "saved_model = load_model('bestModel.h5')\n",
    "\n",
    "X = ratingsTestLargeDataframe[['UserID', 'ItemID']].values\n",
    "X_validation_array = [X[:, 0], X[:, 1]]\n",
    "\n",
    "ratingsTestLargeDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#saved_model = load_model('bestModel.h5')\n",
    "#_, test_acc = saved_model.evaluate(X, y, verbose=0)\n",
    "\n",
    "# Generate predictions for samples\n",
    "predictions = saved_model.predict(X_validation_array)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_number(number):\n",
    "    return round(number *2) /2\n",
    "\n",
    "#roundedPredictions = [roundedPredictions.append(round_number(y) for y in x in predictions]\n",
    "#Then for arr in array: first?\n",
    "roundedPredictions=[]\n",
    "\n",
    "#for x in assignmentTraining_text['tweetText'].str.split():\n",
    "#    for i in x:\n",
    "#        corpus.append(i)\n",
    "        \n",
    "for x in predictions:\n",
    "    for y in x:\n",
    "        roundedPredictions.append(round_number(y))\n",
    "\n",
    "\n",
    "ratingsTestLargeDataframe['Rating'] = roundedPredictions\n",
    "ratingsTestLargeDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTestLargeDataframe['UserID'] = user_encoderLargeTest.inverse_transform(ratingsTestLargeDataframe['UserID'].values)\n",
    "ratingsTestLargeDataframe['ItemID'] = item_encoderLargeTest.inverse_transform(ratingsTestLargeDataframe['ItemID'].values)\n",
    "ratingsTestLargeDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56634edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTestLargeDataframe.to_csv('predictionsLarge.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152f2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a170a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18848c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
